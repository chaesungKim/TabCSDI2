{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# census onehot PROBLEM\n",
    "onehot: MCAR은 정상 작동, MAR, MNAR train도 가능 but evaluate할 때 코드가 돌아가지 않음. 원인은 tensor size가 맞지 않음.\n",
    "- main_model_table.py의 evaluate에서 문제 발생\n",
    "- batch에 대해 process_data(TabCSDI 클래스에 선언) 했을 때 문제가 생기는지. \n",
    "- evaluate_onehot에 문제가 있나? 근데 MCAR일 때는 왜 아무런 문제가 없냐고.\n",
    "- What to demonstrate: 1. Onehot - MCAR과의 차이 2. FT, Analog와의 차이\n",
    "- 207 = 15 + 96 + 96 = 111 + 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# import required packages\n",
    "import torch\n",
    "# import wget\n",
    "# wget.download('https://raw.githubusercontent.com/BorisMuzellec/MissingDataOT/master/utils.py')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import datetime\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from src.main_model_table import TabCSDI\n",
    "from src.utils_table import train, evaluate_onehot\n",
    "from dataset_census.dataset_census_onehot2 import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "modelfolder = \"census_onehot_fold5/MAR0.4_20240225_070242/\"\n",
    "testmissingratio = 0.2\n",
    "config = \"census_onehot_analog.yaml\"\n",
    "# device = \"cuda\"\n",
    "if torch.cuda.is_available() : device = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available() : device = torch.device('mps')\n",
    "else : device=torch.device('cpu')\n",
    "print(f'Using {device}')\n",
    "exe_name = \"census\"\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "path = \"config/\" + config\n",
    "with open(path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config[\"model\"][\"is_unconditional\"] = 0\n",
    "config[\"model\"][\"test_missing_ratio\"] = testmissingratio\n",
    "model = TabCSDI(config, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Dataset created--------\n",
      "Dataset size:20000 entries\n",
      "--------------Dataset has not been normalized yet. Perform data normalization and store the mean value of each column.--------------\n",
      "--------------Max-value for cont-variable column [9.000000e+01 1.484705e+06 1.600000e+01 9.999900e+04 4.356000e+03\n",
      " 9.900000e+01]--------------\n",
      "--------------Min-value for cont-variable column [1.7000e+01 1.9302e+04 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00]--------------\n",
      "--------Normalized dataset loaded--------\n",
      "--------Normalized dataset loaded--------\n",
      "--------Normalized dataset loaded--------\n",
      "Training dataset size: 16000\n",
      "Validation dataset size: 0\n",
      "Testing dataset size: 4000\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = get_dataloader(\n",
    "    seed=2,\n",
    "    nfold=5,\n",
    "    batch_size=64,\n",
    "    missing_ratio=0.4,\n",
    "    mecha=\"MAR\",\n",
    "    opt=\"logistic\",\n",
    "    p_obs=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/63 [00:00<00:00, 90.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'observed_data': tensor([[ 0.0541,  0.1763,  0.0625,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.0946,  0.1135,  0.8125,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.4865,  0.0929,  0.5625,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.1757,  0.0459,  0.1250,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.2973,  0.0968,  0.6250,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.3108,  0.1174,  0.8125,  ..., -1.0000, -1.0000,  1.0000]],\n",
      "       dtype=torch.float64), 'observed_mask': tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]]), 'gt_mask': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64), 'timepoints': tensor([[  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        ...,\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110]])}\n",
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'timepoints'])\n",
      "2 {'observed_data': tensor([[ 0.2703,  0.1338,  0.8125,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.1622,  0.0912,  0.5625,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.4324,  0.1061,  0.7500,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.1216,  0.1691,  0.6250,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.0811,  0.0569,  0.6250,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.0946,  0.0237,  0.5625,  ..., -1.0000,  1.0000, -1.0000]],\n",
      "       dtype=torch.float64), 'observed_mask': tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]]), 'gt_mask': tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64), 'timepoints': tensor([[  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        ...,\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110]])}\n",
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'timepoints'])\n",
      "3 {'observed_data': tensor([[ 0.3108,  0.1064,  0.6250,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.5541,  0.0102,  0.5625,  ..., -1.0000, -1.0000,  1.0000],\n",
      "        [ 0.3243,  0.0355,  0.5625,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        ...,\n",
      "        [ 0.0541,  0.0941,  0.6250,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.3784,  0.0628,  0.5625,  ..., -1.0000,  1.0000, -1.0000],\n",
      "        [ 0.1081,  0.1097,  0.7500,  ..., -1.0000,  1.0000, -1.0000]],\n",
      "       dtype=torch.float64), 'observed_mask': tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]]), 'gt_mask': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]], dtype=torch.float64), 'timepoints': tensor([[  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        ...,\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110],\n",
      "        [  0,   1,   2,  ..., 108, 109, 110]])}\n",
      "dict_keys(['observed_data', 'observed_mask', 'gt_mask', 'timepoints'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "torch.manual_seed(0);np.random.seed(0)\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, mininterval=5.0, maxinterval=50.0) as it:\n",
    "        for batch_no, test_batch in enumerate(it, start=1):\n",
    "            print(batch_no, test_batch)\n",
    "            print(test_batch.keys())\n",
    "            if batch_no == 3:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 111])\n",
      "torch.Size([64, 111])\n"
     ]
    }
   ],
   "source": [
    "print(test_batch['observed_mask'].shape)\n",
    "print(test_batch['gt_mask'].shape)\n",
    "## 아..???\n",
    "## test_loader 생성 시 gt_mask를 만들 때 무슨 문제가 있나. 왜 하필 Onehot, MAR만 이러나. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate 풀어서 쓰기\n",
    "# process_data\n",
    "batch = test_batch\n",
    "observed_data = batch[\"observed_data\"][:, np.newaxis, :].to(device).float()\n",
    "observed_mask = batch[\"observed_mask\"][:, np.newaxis, :].to(device).float()\n",
    "observed_tp = batch[\"timepoints\"].to(device).float()\n",
    "gt_mask = batch[\"gt_mask\"][:, np.newaxis, :].to(device).float()\n",
    "cut_length = torch.zeros(len(observed_data)).long().to(device)\n",
    "for_pattern_mask = observed_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 111])\n",
      "torch.Size([64, 1, 111])\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "print(gt_mask.shape)\n",
    "print(observed_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (111) must match the size of tensor b (207) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     cond_mask \u001b[38;5;241m=\u001b[39m gt_mask\n\u001b[0;32m----> 3\u001b[0m     target_mask \u001b[38;5;241m=\u001b[39m \u001b[43mobserved_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcond_mask\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cond_mask\u001b[38;5;241m.\u001b[39mshape, target_mask\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (111) must match the size of tensor b (207) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    cond_mask = gt_mask\n",
    "    target_mask = observed_mask - cond_mask\n",
    "    print(cond_mask.shape, target_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 데이터셋을 처리해 gt_mask를 생성하는 process_func를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_NA(X, p_miss, mecha=\"MAR\", opt=None, p_obs=None, q=None):\n",
    "    \n",
    "    to_torch = torch.is_tensor(X)\n",
    "    \n",
    "    if not to_torch:\n",
    "        X = X.astype(np.float32)\n",
    "        X = torch.from_numpy(X)\n",
    "    \n",
    "    np.random.seed(0);torch.manual_seed(0)\n",
    "    if mecha == \"MAR\":\n",
    "        mask = MAR_mask(X, p_miss, p_obs).double()\n",
    "    elif mecha == \"MNAR\" and opt == \"logistic\":\n",
    "        mask = MNAR_mask_logistic(X, p_miss, p_obs).double()\n",
    "    elif mecha == \"MNAR\" and opt == \"quantile\":\n",
    "        mask = MNAR_mask_quantiles(X, p_miss, q, 1-p_obs).double()\n",
    "    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n",
    "        mask = MNAR_self_mask_logistic(X, p_miss).double()\n",
    "    else:\n",
    "        mask = (torch.rand(X.shape) < p_miss).double()\n",
    "    \n",
    "    # X_nas = X.clone()\n",
    "    # X_nas[mask.bool()] = np.nan\n",
    "    \n",
    "    # return X_nas.double() # tensor type\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data_census_onehot/adult_trim.data'\n",
    "missing_ratio = 0.4\n",
    "encode = True\n",
    "p_obs = 0.5\n",
    "mecha = 'MAR'\n",
    "opt = 'logistic'\n",
    "cat_list = [1, 3, 5, 6, 7, 8, 9, 13, 14]\n",
    "\n",
    "data = pd.read_csv(path, header=None)\n",
    "data.replace(\" ?\", np.nan, inplace=True)\n",
    "\n",
    "temp_list = [i for i in range(data.shape[1]) if i not in cat_list]\n",
    "temp_list.extend(cat_list)\n",
    "new_cols_order = temp_list\n",
    "data = data.reindex(columns=data.columns[new_cols_order])\n",
    "data.columns = [i for i in range(data.shape[1])]\n",
    "\n",
    "# create two lists to store position\n",
    "cont_list = [i for i in range(0, data.shape[1] - len(cat_list))]\n",
    "cat_list = [i for i in range(len(cont_list), data.shape[1])]\n",
    "\n",
    "observed_values = data.values\n",
    "observed_masks = ~pd.isnull(data)\n",
    "observed_masks = observed_masks.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder2 = ce.ordinal.OrdinalEncoder(cols=data.columns[cat_list]) ## ordinal encoding\n",
    "encoder2.fit(data)\n",
    "new_df2 = encoder2.transform(data)\n",
    "new_observed_values2 = new_df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks = produce_NA(new_observed_values2, p_miss=missing_ratio, p_obs=p_obs, mecha=mecha, opt=opt)\n",
    "gt_masks = np.array(gt_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.one_hot.OneHotEncoder(cols=data.columns[cat_list]) ## one hot encoding\n",
    "encoder.fit(data)\n",
    "new_df = encoder.transform(data)\n",
    "\n",
    "# we now need to transform these masks to the new one, suitable for mixed data types.\n",
    "cum_num_bits = 0\n",
    "new_observed_masks = observed_masks.copy()\n",
    "new_gt_masks = gt_masks.copy()\n",
    "\n",
    "for index, col in enumerate(cat_list):\n",
    "    corresponding_cols = len(\n",
    "        [\n",
    "            s\n",
    "            for s in new_df.columns\n",
    "            if isinstance(s, str) and s.startswith(str(col) + \"_\")\n",
    "        ]\n",
    "    )\n",
    "    add_col_num = corresponding_cols\n",
    "    insert_col_obs = observed_masks[:, col] ## masked columns(variables)\n",
    "    insert_col_gt = gt_masks[:, col]\n",
    "\n",
    "    for i in range(add_col_num - 1): ## transform masked columns into the form of one hot encoded columns\n",
    "        new_observed_masks = np.insert(\n",
    "            new_observed_masks, cum_num_bits + col, insert_col_obs, axis=1\n",
    "        )\n",
    "        new_gt_masks = np.insert(\n",
    "            new_gt_masks, cum_num_bits + col, insert_col_gt, axis=1\n",
    "        )\n",
    "    cum_num_bits += add_col_num - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/41dsh9496q37sbz08xw3rgkr0000gn/T/ipykernel_67091/570892538.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_observed_values = new_observed_values.astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "new_observed_values = new_df.values\n",
    "new_observed_values_cat = new_observed_values[:, len(cont_list) :]\n",
    "index = new_observed_values_cat == 0\n",
    "new_observed_values_cat[index] = -1\n",
    "new_observed_values[:, len(cont_list) :] = new_observed_values_cat\n",
    "new_observed_values = np.nan_to_num(new_observed_values)\n",
    "new_observed_values = new_observed_values.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 111)\n",
      "(20000, 111)\n"
     ]
    }
   ],
   "source": [
    "print(new_gt_masks.shape)\n",
    "print(new_observed_masks.shape)\n",
    "# process_func은 문제 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Normalized dataset loaded--------\n",
      "<dataset_census.dataset_census_onehot2.tabular_dataset object at 0x173fae1c0>\n"
     ]
    }
   ],
   "source": [
    "# get_dataloader\n",
    "from dataset_census.dataset_census_onehot2 import tabular_dataset\n",
    "\n",
    "dataset = tabular_dataset(missing_ratio=0.4, seed=1, p_obs=0.5, mecha='MAR', opt='logistic')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "indlist = np.arange(len(dataset))\n",
    "\n",
    "np.random.seed(2)\n",
    "np.random.shuffle(indlist)\n",
    "\n",
    "tmp_ratio = 1/5\n",
    "start = (int)(4 * len(dataset) * tmp_ratio)\n",
    "end = start + int(len(dataset) * tmp_ratio)\n",
    "test_index = indlist[start:end]\n",
    "remain_index = np.delete(indlist, np.arange(start, end))\n",
    "\n",
    "np.random.shuffle(remain_index)\n",
    "num_train = (int)(len(remain_index)*1)\n",
    "train_index = remain_index[:num_train]\n",
    "valid_index = remain_index[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  836,  1849, 16673, ..., 11798,  6637,  2575])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론: 예전에 데이터 생성 함수를 잘못 만들었었는데, 그때의 시드로 만들어진 데이터가 계속 사용되고 있었음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래도 다시 확인\n",
    "import io\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "          return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_census_onehot/missing_ratio-0.4_seed-1.pk\", 'rb') as f :\n",
    "    oh_data = CPU_Unpickler(f).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 111)\n",
      "(20000, 111)\n",
      "(20000, 207)\n"
     ]
    }
   ],
   "source": [
    "print(oh_data[0].shape)\n",
    "print(oh_data[1].shape)\n",
    "print(oh_data[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .pk 만들어보까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Dataset created--------\n",
      "Dataset size:20000 entries\n",
      "--------------Dataset has not been normalized yet. Perform data normalization and store the mean value of each column.--------------\n",
      "--------------Max-value for cont-variable column [9.000000e+01 1.484705e+06 1.600000e+01 9.999900e+04 4.356000e+03\n",
      " 9.900000e+01]--------------\n",
      "--------------Min-value for cont-variable column [1.7000e+01 1.2285e+04 1.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00]--------------\n",
      "--------Normalized dataset loaded--------\n",
      "--------Normalized dataset loaded--------\n",
      "--------Normalized dataset loaded--------\n",
      "Training dataset size: 16000\n",
      "Validation dataset size: 0\n",
      "Testing dataset size: 4000\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = get_dataloader(\n",
    "    seed=1,\n",
    "    nfold=5,\n",
    "    batch_size=64,\n",
    "    missing_ratio=0.4,\n",
    "    mecha=\"MAR\",\n",
    "    opt=\"logistic\",\n",
    "    p_obs=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>36</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>89622</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>202498</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Dominican-Republic</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>72</td>\n",
       "      <td>Private</td>\n",
       "      <td>268861</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>?</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>343242</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>460408</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                  1       2              3   4                    5   \\\n",
       "0      39          State-gov   77516      Bachelors  13        Never-married   \n",
       "1      50   Self-emp-not-inc   83311      Bachelors  13   Married-civ-spouse   \n",
       "2      38            Private  215646        HS-grad   9             Divorced   \n",
       "3      53            Private  234721           11th   7   Married-civ-spouse   \n",
       "4      28            Private  338409      Bachelors  13   Married-civ-spouse   \n",
       "...    ..                ...     ...            ...  ..                  ...   \n",
       "19995  36   Self-emp-not-inc   89622        HS-grad   9   Married-civ-spouse   \n",
       "19996  34            Private  202498           12th   8   Married-civ-spouse   \n",
       "19997  72            Private  268861        7th-8th   4              Widowed   \n",
       "19998  54            Private  343242   Some-college  10   Married-civ-spouse   \n",
       "19999  30            Private  460408        HS-grad   9   Married-civ-spouse   \n",
       "\n",
       "                       6               7       8        9     10  11  12  \\\n",
       "0            Adm-clerical   Not-in-family   White     Male  2174   0  40   \n",
       "1         Exec-managerial         Husband   White     Male     0   0  13   \n",
       "2       Handlers-cleaners   Not-in-family   White     Male     0   0  40   \n",
       "3       Handlers-cleaners         Husband   Black     Male     0   0  40   \n",
       "4          Prof-specialty            Wife   Black   Female     0   0  40   \n",
       "...                   ...             ...     ...      ...   ...  ..  ..   \n",
       "19995        Craft-repair         Husband   White     Male     0   0  80   \n",
       "19996       Other-service         Husband   White     Male     0   0  40   \n",
       "19997       Other-service   Not-in-family   White   Female     0   0  99   \n",
       "19998     Exec-managerial         Husband   White     Male     0   0  44   \n",
       "19999        Craft-repair         Husband   White     Male     0   0  40   \n",
       "\n",
       "                        13      14  \n",
       "0            United-States   <=50K  \n",
       "1            United-States   <=50K  \n",
       "2            United-States   <=50K  \n",
       "3            United-States   <=50K  \n",
       "4                     Cuba   <=50K  \n",
       "...                    ...     ...  \n",
       "19995        United-States    >50K  \n",
       "19996   Dominican-Republic   <=50K  \n",
       "19997                    ?   <=50K  \n",
       "19998        United-States    >50K  \n",
       "19999        United-States    >50K  \n",
       "\n",
       "[20000 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_census_ft/adult_trim.data',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_func in dataset_insurance_ft2.py\n",
    "cat_list = [1,3,5,6,7,8,9,13,14]\n",
    "# Swap columns\n",
    "temp_list = [i for i in range(data.shape[1]) if i not in cat_list]\n",
    "temp_list.extend(cat_list)\n",
    "new_cols_order = temp_list\n",
    "data = data.reindex(columns=data.columns[new_cols_order])\n",
    "data.columns = [i for i in range(data.shape[1])]\n",
    "\n",
    "# create two lists to store position\n",
    "cont_list = [i for i in range(0, data.shape[1] - len(cat_list))]\n",
    "cat_list = [i for i in range(len(cont_list), data.shape[1])]\n",
    "\n",
    "observed_values = data.values\n",
    "observed_masks = ~pd.isnull(data)\n",
    "observed_masks = observed_masks.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from category_encoders) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from category_encoders) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from category_encoders) (1.9.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from category_encoders) (1.5.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is for generating .pk file for mixed data types dataset\n",
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# import required packages\n",
    "import torch\n",
    "# import wget\n",
    "# wget.download('https://raw.githubusercontent.com/BorisMuzellec/MissingDataOT/master/utils.py')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_NA(X, p_miss, mecha=\"MAR\", opt=None, p_obs=None, q=None):\n",
    "    \n",
    "    to_torch = torch.is_tensor(X)\n",
    "    \n",
    "    if not to_torch:\n",
    "        X = X.astype(np.float32)\n",
    "        X = torch.from_numpy(X)\n",
    "    \n",
    "    np.random.seed(0);torch.manual_seed(0)\n",
    "    if mecha == \"MAR\":\n",
    "        mask = MAR_mask(X, p_miss, p_obs).double()\n",
    "    elif mecha == \"MNAR\" and opt == \"logistic\":\n",
    "        mask = MNAR_mask_logistic(X, p_miss, p_obs).double()\n",
    "    elif mecha == \"MNAR\" and opt == \"quantile\":\n",
    "        mask = MNAR_mask_quantiles(X, p_miss, q, 1-p_obs).double()\n",
    "    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n",
    "        mask = MNAR_self_mask_logistic(X, p_miss).double()\n",
    "    else:\n",
    "        mask = (torch.rand(X.shape) < p_miss).double()\n",
    "    \n",
    "    # X_nas = X.clone()\n",
    "    # X_nas[mask.bool()] = np.nan\n",
    "    \n",
    "    # return X_nas.double() # tensor type\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    39  77516     13 ...      1      1      1]\n",
      " [    50  83311     13 ...      1      1      1]\n",
      " [    38 215646      9 ...      1      1      1]\n",
      " ...\n",
      " [    72 268861      4 ...      2      5      1]\n",
      " [    54 343242     10 ...      1      1      2]\n",
      " [    30 460408      9 ...      1      1      2]]\n"
     ]
    }
   ],
   "source": [
    "encoder = ce.ordinal.OrdinalEncoder(cols=data.columns[cat_list])\n",
    "encoder.fit(data)\n",
    "new_df = encoder.transform(data)\n",
    "new_observed_values = new_df.values\n",
    "print(new_observed_values)\n",
    "\n",
    "missing_ratio=0.2\n",
    "p_obs=None\n",
    "mecha='MCAR'\n",
    "opt=None\n",
    "gt_masks = produce_NA(new_observed_values, p_miss=missing_ratio, p_obs=p_obs, mecha=mecha, opt=opt)\n",
    "gt_masks = np.array(gt_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>36</td>\n",
       "      <td>89622</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>34</td>\n",
       "      <td>202498</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>72</td>\n",
       "      <td>268861</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>54</td>\n",
       "      <td>343242</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>30</td>\n",
       "      <td>460408</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1   2     3   4   5   6   7   8   9   10  11  12  13  14\n",
       "0      39   77516  13  2174   0  40   1   1   1   1   1   1   1   1   1\n",
       "1      50   83311  13     0   0  13   2   1   2   2   2   1   1   1   1\n",
       "2      38  215646   9     0   0  40   3   2   3   3   1   1   1   1   1\n",
       "3      53  234721   7     0   0  40   3   3   2   3   2   2   1   1   1\n",
       "4      28  338409  13     0   0  40   3   1   2   4   3   2   2   2   1\n",
       "...    ..     ...  ..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "19995  36   89622   9     0   0  80   2   2   2   7   2   1   1   1   2\n",
       "19996  34  202498   8     0   0  40   3  16   2   5   2   1   1  25   1\n",
       "19997  72  268861   4     0   0  99   3   9   7   5   1   1   2   5   1\n",
       "19998  54  343242  10     0   0  44   3   6   2   2   2   1   1   1   2\n",
       "19999  30  460408   9     0   0  40   3   2   2   7   2   1   1   1   2\n",
       "\n",
       "[20000 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_observed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for insurance data\n",
    "data = pd.read_csv('./data_insurance/insurance.csv',header=None)\n",
    "# process_func in dataset_insurance_ft2.py\n",
    "cat_list = [1,4,5]\n",
    "# Swap columns\n",
    "temp_list = [i for i in range(data.shape[1]) if i not in cat_list]\n",
    "temp_list.extend(cat_list)\n",
    "new_cols_order = temp_list\n",
    "data = data.reindex(columns=data.columns[new_cols_order])\n",
    "data.columns = [i for i in range(data.shape[1])]\n",
    "\n",
    "# create two lists to store position\n",
    "cont_list = [i for i in range(0, data.shape[1] - len(cat_list))]\n",
    "cat_list = [i for i in range(len(cont_list), data.shape[1])]\n",
    "\n",
    "observed_values = data.values\n",
    "observed_masks = ~pd.isnull(data)\n",
    "observed_masks = observed_masks.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.   27.9   0.   ...  1.    1.    1.  ]\n",
      " [18.   33.77  1.   ...  2.    2.    2.  ]\n",
      " [28.   33.    3.   ...  2.    2.    2.  ]\n",
      " ...\n",
      " [18.   36.85  0.   ...  1.    2.    2.  ]\n",
      " [21.   25.8   0.   ...  1.    2.    1.  ]\n",
      " [61.   29.07  0.   ...  1.    1.    3.  ]]\n"
     ]
    }
   ],
   "source": [
    "encoder = ce.ordinal.OrdinalEncoder(cols=data.columns[cat_list])\n",
    "encoder.fit(data)\n",
    "new_df = encoder.transform(data)\n",
    "new_observed_values = new_df.values\n",
    "print(new_observed_values)\n",
    "\n",
    "gt_masks = produce_NA(new_observed_values, p_miss=missing_ratio, p_obs=p_obs, mecha=mecha, opt=opt)\n",
    "gt_masks = np.array(gt_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.9</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.77</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.5523</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.462</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.88</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.8552</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.97</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.5483</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.92</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.9808</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.85</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.8335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.8</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.945</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.07</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.3603</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1          2            3  4  5  6\n",
       "0     19    27.9  southwest    16884.924  1  1  1\n",
       "1     18   33.77  southeast    1725.5523  2  2  2\n",
       "2     28    33.0  southeast     4449.462  2  3  2\n",
       "3     33  22.705  northwest  21984.47061  2  1  2\n",
       "4     32   28.88  northwest    3866.8552  2  1  2\n",
       "...   ..     ...        ...          ... .. .. ..\n",
       "1333  50   30.97  northwest   10600.5483  2  3  2\n",
       "1334  18   31.92  northeast    2205.9808  1  1  2\n",
       "1335  18   36.85  southeast    1629.8335  1  1  2\n",
       "1336  21    25.8  southwest     2007.945  1  1  2\n",
       "1337  61   29.07  northwest   29141.3603  1  1  1\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_observed_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
